<div align="center">

# üîé Toxic Comment Classifier

### *Clasificador Inteligente de Comentarios T√≥xicos con Machine Learning*

[![Python](https://img.shields.io/badge/Python-3.11-blue.svg)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.48.1-FF4B4B.svg)](https://streamlit.io/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.116.1-009688.svg)](https://fastapi.tiangolo.com/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.7.1-F7931E.svg)](https://scikit-learn.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

**Aplicaci√≥n completa de Machine Learning para detectar y clasificar toxicidad en comentarios de texto.**

[Demo](#-demo-r√°pida) ‚Ä¢ [Caracter√≠sticas](#-caracter√≠sticas-principales) ‚Ä¢ [Instalaci√≥n](#-instalaci√≥n) ‚Ä¢ [API](#-api-rest) ‚Ä¢ [Documentaci√≥n](#-estructura-del-proyecto)

</div>

---

## üìã Descripci√≥n

**Toxic Comment Classifier** es una soluci√≥n end-to-end de **procesamiento de lenguaje natural (NLP)** que identifica autom√°ticamente contenido t√≥xico, ofensivo o inapropiado en comentarios escritos en ingl√©s. El sistema combina dos niveles de an√°lisis:

üéØ **Clasificaci√≥n Binaria**: Determina si un comentario es t√≥xico o no t√≥xico  
üî¨ **An√°lisis Multi-etiqueta**: Identifica hasta **29 categor√≠as espec√≠ficas** de toxicidad

### üí° Casos de Uso

- **Moderaci√≥n de Contenido**: Filtrado autom√°tico en redes sociales, foros y blogs
- **An√°lisis de Sentimiento**: Evaluaci√≥n de feedback y comentarios de usuarios
- **Investigaci√≥n**: Estudio de patrones de lenguaje ofensivo y comportamiento online
- **Sistemas de Alerta**: Detecci√≥n temprana de amenazas o acoso

---

## ‚ú® Caracter√≠sticas Principales

### ü§ñ Clasificaci√≥n Inteligente

- **Modelo B√°sico**: Clasificaci√≥n binaria r√°pida (T√≥xico/No T√≥xico)
- **Modelo Detallado**: An√°lisis multi-etiqueta con 29 categor√≠as:
  - `obscene`, `insult`, `threat`, `identity_attack`
  - Identidades espec√≠ficas: `racial`, `religious`, `gender`, `sexual_orientation`
  - `sexual_explicit` y muchas m√°s

### üñ•Ô∏è Interfaz Web Interactiva (Streamlit)

- **UI Amigable**: Interfaz limpia y responsive
- **An√°lisis en Tiempo Real**: Resultados instant√°neos con m√©tricas de confianza
- **Visualizaci√≥n Avanzada**: 
  - Probabilidades de clasificaci√≥n
  - Categor√≠as detectadas con niveles de confianza
  - Indicadores visuales de alerta

### üöÄ API REST (FastAPI)

- **Endpoints RESTful**: Integraci√≥n f√°cil con otros sistemas
- **Autenticaci√≥n**: HTTP Basic Auth con rate limiting
- **Documentaci√≥n Autom√°tica**: Swagger UI en `/docs`
- **Batch Processing**: Clasificaci√≥n de m√∫ltiples comentarios

### üìä Pipeline ML Completo

- **Notebooks Jupyter**: Exploraci√≥n de datos, entrenamiento y evaluaci√≥n
- **Modelos Persistidos**: Artifacts listos para producci√≥n
- **Reproducibilidad**: Scripts de smoke test y validaci√≥n

---

## üöÄ Demo R√°pida

### Opci√≥n 1: Streamlit App

```bash
# Clonar repositorio
git clone https://github.com/tu-usuario/toxic-comment-classifier.git
cd toxic-comment-classifier

# Instalar dependencias
pip install -r requirements.txt

# Ejecutar aplicaci√≥n
streamlit run app/app.py
```

Abre `http://localhost:8501` en tu navegador y ¬°empieza a clasificar!

### Opci√≥n 2: Docker

```bash
# Construir imagen
docker build -t toxic-classifier .

# Ejecutar contenedor
docker run -p 8501:8501 toxic-classifier
```

### Opci√≥n 3: API REST

```bash
# Ejecutar API
python run_api.py

# Acceder a documentaci√≥n
# http://localhost:8000/docs
```

---

## üíª Instalaci√≥n

### Requisitos Previos

- Python 3.11+
- pip
- (Opcional) Docker

### Paso a Paso

1. **Clonar el repositorio**
```bash
git clone https://github.com/tu-usuario/toxic-comment-classifier.git
cd toxic-comment-classifier
```

2. **Crear entorno virtual**
```bash
# Windows
python -m venv venv
.\venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

3. **Instalar dependencias**
```bash
pip install -r requirements.txt
```

4. **Verificar instalaci√≥n**
```bash
python scripts/smoke_test.py
```

---

## üéÆ Uso

### Interfaz Web (Streamlit)

```bash
streamlit run app/app.py
```

**Funcionalidades:**
- ‚úçÔ∏è Escribe o pega cualquier comentario
- üîç Click en "Clasificar Comentario"
- üìä Visualiza resultados con probabilidades
- üî¨ Activa "An√°lisis Detallado" para comentarios t√≥xicos

### API REST (FastAPI)

**Iniciar servidor:**
```bash
python run_api.py
# API disponible en http://localhost:8000
```

**Ejemplo de uso:**

```python
import requests
from requests.auth import HTTPBasicAuth

url = "http://localhost:8000/classify"
auth = HTTPBasicAuth("admin", "secret123")

response = requests.post(
    url,
    json={
        "text": "You are an idiot!",
        "include_probability": True,
        "include_detailed_classification": True
    },
    auth=auth
)

print(response.json())
```

**Endpoints disponibles:**
- `POST /classify` - Clasificar comentario individual
- `POST /classify-batch` - Clasificaci√≥n por lotes
- `GET /health` - Estado del sistema
- `GET /stats` - Estad√≠sticas de uso
- `GET /docs` - Documentaci√≥n interactiva (Swagger)

### Uso Program√°tico

```python
import joblib

# Cargar modelos
vectorizer = joblib.load('artifacts/vectorizer.pkl')
clf = joblib.load('artifacts/model.pkl')

# Clasificar
comment = "This is a great article!"
X = vectorizer.transform([comment])
prediction = clf.predict(X)[0]
probability = clf.predict_proba(X)[0]

print(f"Toxic: {bool(prediction)}")
print(f"Confidence: {probability[1]:.2%}")
```

---

## üèóÔ∏è Estructura del Proyecto

```
toxic-comment-classifier/
‚îÇ
‚îú‚îÄ‚îÄ üìÅ app/                          # Aplicaci√≥n Streamlit
‚îÇ   ‚îî‚îÄ‚îÄ app.py                       # Interfaz web principal
‚îÇ
‚îú‚îÄ‚îÄ üìÅ api/                          # API REST
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ main.py                      # Endpoints FastAPI
‚îÇ
‚îú‚îÄ‚îÄ üìÅ artifacts/                    # Modelos entrenados
‚îÇ   ‚îú‚îÄ‚îÄ model.pkl                    # Modelo b√°sico
‚îÇ   ‚îú‚îÄ‚îÄ vectorizer.pkl               # TF-IDF vectorizador
‚îÇ   ‚îú‚îÄ‚îÄ detailed_model.pkl           # Modelo multi-etiqueta
‚îÇ   ‚îú‚îÄ‚îÄ vectorizer_detailed.pkl      # Vectorizador detallado
‚îÇ   ‚îî‚îÄ‚îÄ toxicity_categories.pkl      # Lista de categor√≠as
‚îÇ
‚îú‚îÄ‚îÄ üìÅ notebooks/                    # An√°lisis y entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ 01_exploracion_dataset.ipynb     # EDA
‚îÇ   ‚îú‚îÄ‚îÄ 02_entrenamiento_modelo.ipynb    # Modelo b√°sico
‚îÇ   ‚îú‚îÄ‚îÄ 03_guardar_modelo.ipynb          # Persistencia
‚îÇ   ‚îî‚îÄ‚îÄ 04_modelo_clasificacion_detallada.ipynb  # Modelo multi-etiqueta
‚îÇ
‚îú‚îÄ‚îÄ üìÅ data/                         # Datasets (local)
‚îÇ   ‚îî‚îÄ‚îÄ data.csv
‚îÇ
‚îú‚îÄ‚îÄ üìÅ scripts/                      # Utilidades
‚îÇ   ‚îî‚îÄ‚îÄ smoke_test.py                # Tests de validaci√≥n
‚îÇ
‚îú‚îÄ‚îÄ üìÑ requirements.txt              # Dependencias Python
‚îú‚îÄ‚îÄ üìÑ Dockerfile                    # Configuraci√≥n Docker
‚îú‚îÄ‚îÄ üìÑ run_api.py                    # Script para ejecutar API
‚îî‚îÄ‚îÄ üìÑ README.md                     # Este archivo
```

---

## üõ†Ô∏è Stack Tecnol√≥gico

### Machine Learning & Data Science
- **scikit-learn** `1.7.1` - Modelos de clasificaci√≥n (Logistic Regression)
- **pandas** `2.3.2` - Manipulaci√≥n de datos
- **numpy** `2.3.2` - Operaciones num√©ricas
- **joblib** `1.5.1` - Serializaci√≥n de modelos

### Frameworks Web
- **Streamlit** `1.48.1` - Interfaz web interactiva
- **FastAPI** `0.116.1` - API REST de alto rendimiento
- **Uvicorn** `0.35.0` - Servidor ASGI

### Visualizaci√≥n
- **matplotlib** `3.10.5` - Gr√°ficos est√°ticos
- **Altair** `5.5.0` - Visualizaciones interactivas

### Otros
- **PyJWT** `2.8.0` - Autenticaci√≥n JWT
- **cryptography** `41.0.7` - Seguridad
- **Docker** - Containerizaci√≥n

---

## üìä Rendimiento del Modelo

### Modelo B√°sico (Binario)
- **Algoritmo**: Logistic Regression
- **Vectorizaci√≥n**: TF-IDF (10,000 features)
- **Accuracy**: ~92%
- **Vocabulario**: 10,000 palabras

### Modelo Detallado (Multi-etiqueta)
- **Algoritmo**: MultiOutputClassifier + Logistic Regression
- **Vectorizaci√≥n**: TF-IDF extendido
- **Categor√≠as**: 29 tipos de toxicidad
- **Vocabulario**: 10,000+ palabras

---

## üîê Seguridad

### API
- Autenticaci√≥n HTTP Basic (usuario/contrase√±a)
- Rate Limiting: 100 requests/minuto por usuario
- Validaci√≥n de entrada con Pydantic

### Producci√≥n
> ‚ö†Ô∏è **Nota**: Este proyecto es educativo/demostrativo. Para producci√≥n:
> - Implementar autenticaci√≥n robusta (OAuth2, JWT)
> - Usar base de datos para credenciales
> - Configurar CORS espec√≠fico
> - Implementar rate limiting con Redis
> - Agregar logging y monitoreo
> - Usar HTTPS

---

## üß™ Testing

### Smoke Test
```bash
python scripts/smoke_test.py
```

Verifica:
- ‚úÖ Carga correcta de todos los artifacts
- ‚úÖ Funcionalidad de predicci√≥n b√°sica
- ‚úÖ Funcionalidad de predicci√≥n detallada
- ‚úÖ Integridad del vocabulario

---

## üìö Notebooks

### 1. Exploraci√≥n del Dataset
`notebooks/01_exploracion_dataset.ipynb`
- An√°lisis exploratorio de datos (EDA)
- Distribuci√≥n de clases
- An√°lisis de palabras frecuentes

### 2. Entrenamiento Modelo B√°sico
`notebooks/02_entrenamiento_modelo.ipynb`
- Preprocesamiento de texto
- Vectorizaci√≥n TF-IDF
- Entrenamiento Logistic Regression
- Evaluaci√≥n de m√©tricas

### 3. Guardar Modelos
`notebooks/03_guardar_modelo.ipynb`
- Serializaci√≥n con joblib
- Validaci√≥n de artifacts

### 4. Clasificaci√≥n Detallada
`notebooks/04_modelo_clasificacion_detallada.ipynb`
- Modelo multi-etiqueta
- 29 categor√≠as de toxicidad
- An√°lisis granular

---

## üö¢ Despliegue

### Local
```bash
streamlit run app/app.py
```

### Docker
```bash
docker build -t toxic-classifier .
docker run -p 8501:8501 toxic-classifier
```

### Streamlit Cloud
1. Sube el repo a GitHub
2. Conecta con [Streamlit Cloud](https://streamlit.io/cloud)
3. Deploy autom√°tico

### Heroku / Railway / Render
Compatible con cualquier plataforma que soporte Docker

---

## ü§ù Contribuciones

Las contribuciones son bienvenidas! 

1. Fork el proyecto
2. Crea tu feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

---

## üìù Licencia

Este proyecto est√° bajo la Licencia MIT. Ver archivo `LICENSE` para m√°s detalles.

---

## üë®‚Äçüíª Autor

**Daniel Moreno**

- GitHub: [@tu-usuario](https://github.com/tu-usuario)
- LinkedIn: [Tu Perfil](https://linkedin.com/in/tu-perfil)

---

## üôè Agradecimientos

- Dataset basado en [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)
- Inspirado en investigaciones de NLP y moderaci√≥n de contenido
- Comunidad de scikit-learn y Streamlit

---
