<div align="center">

# ğŸ” Toxic Comment Classifier

### *Clasificador Inteligente de Comentarios TÃ³xicos con Machine Learning*

[![Python](https://img.shields.io/badge/Python-3.11-blue.svg)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.48.1-FF4B4B.svg)](https://streamlit.io/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.116.1-009688.svg)](https://fastapi.tiangolo.com/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.7.1-F7931E.svg)](https://scikit-learn.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

**AplicaciÃ³n completa de Machine Learning para detectar y clasificar toxicidad en comentarios de texto.**

[Demo](#-demo-rÃ¡pida) â€¢ [CaracterÃ­sticas](#-caracterÃ­sticas-principales) â€¢ [InstalaciÃ³n](#-instalaciÃ³n) â€¢ [API](#-api-rest) â€¢ [DocumentaciÃ³n](#-estructura-del-proyecto)

</div>

---

## ğŸ“‹ DescripciÃ³n

**Toxic Comment Classifier** es una soluciÃ³n end-to-end de **procesamiento de lenguaje natural (NLP)** que identifica automÃ¡ticamente contenido tÃ³xico, ofensivo o inapropiado en comentarios escritos en inglÃ©s. El sistema combina dos niveles de anÃ¡lisis:

ğŸ¯ **ClasificaciÃ³n Binaria**: Determina si un comentario es tÃ³xico o no tÃ³xico  
ğŸ”¬ **AnÃ¡lisis Multi-etiqueta**: Identifica hasta **29 categorÃ­as especÃ­ficas** de toxicidad

### ğŸ’¡ Casos de Uso

- **ModeraciÃ³n de Contenido**: Filtrado automÃ¡tico en redes sociales, foros y blogs
- **AnÃ¡lisis de Sentimiento**: EvaluaciÃ³n de feedback y comentarios de usuarios
- **InvestigaciÃ³n**: Estudio de patrones de lenguaje ofensivo y comportamiento online
- **Sistemas de Alerta**: DetecciÃ³n temprana de amenazas o acoso

---

## âœ¨ CaracterÃ­sticas Principales

### ğŸ¤– ClasificaciÃ³n Inteligente

- **Modelo BÃ¡sico**: ClasificaciÃ³n binaria rÃ¡pida (TÃ³xico/No TÃ³xico)
- **Modelo Detallado**: AnÃ¡lisis multi-etiqueta con 29 categorÃ­as:
  - `obscene`, `insult`, `threat`, `identity_attack`
  - Identidades especÃ­ficas: `racial`, `religious`, `gender`, `sexual_orientation`
  - `sexual_explicit` y muchas mÃ¡s

### ğŸ–¥ï¸ Interfaz Web Interactiva (Streamlit)

- **UI Amigable**: Interfaz limpia y responsive
- **AnÃ¡lisis en Tiempo Real**: Resultados instantÃ¡neos con mÃ©tricas de confianza
- **VisualizaciÃ³n Avanzada**: 
  - Probabilidades de clasificaciÃ³n
  - CategorÃ­as detectadas con niveles de confianza
  - Indicadores visuales de alerta

### ğŸš€ API REST (FastAPI)

- **Endpoints RESTful**: IntegraciÃ³n fÃ¡cil con otros sistemas
- **AutenticaciÃ³n**: HTTP Basic Auth con rate limiting
- **DocumentaciÃ³n AutomÃ¡tica**: Swagger UI en `/docs`
- **Batch Processing**: ClasificaciÃ³n de mÃºltiples comentarios

### ğŸ“Š Pipeline ML Completo

- **Notebooks Jupyter**: ExploraciÃ³n de datos, entrenamiento y evaluaciÃ³n
- **Modelos Persistidos**: Artifacts listos para producciÃ³n
- **Reproducibilidad**: Scripts de smoke test y validaciÃ³n

---

## ğŸš€ Demo RÃ¡pida

### OpciÃ³n 1: Streamlit App

```bash
# Clonar repositorio
git clone https://github.com/tu-usuario/toxic-comment-classifier.git
cd toxic-comment-classifier

# Instalar dependencias
pip install -r requirements.txt

# Ejecutar aplicaciÃ³n
streamlit run app/app.py
```

Abre `http://localhost:8501` en tu navegador y Â¡empieza a clasificar!

### OpciÃ³n 2: Docker

```bash
# Construir imagen
docker build -t toxic-classifier .

# Ejecutar contenedor
docker run -p 8501:8501 toxic-classifier
```

### OpciÃ³n 3: API REST

```bash
# Ejecutar API
python run_api.py

# Acceder a documentaciÃ³n
# http://localhost:8000/docs
```

---

## ğŸ’» InstalaciÃ³n

### Requisitos Previos

- Python 3.11+
- pip
- (Opcional) Docker

### Paso a Paso

1. **Clonar el repositorio**
```bash
git clone https://github.com/tu-usuario/toxic-comment-classifier.git
cd toxic-comment-classifier
```

2. **Crear entorno virtual**
```bash
# Windows
python -m venv venv
.\venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

3. **Instalar dependencias**
```bash
pip install -r requirements.txt
```

4. **Verificar instalaciÃ³n**
```bash
python scripts/smoke_test.py
```

---

## ğŸ® Uso

### Interfaz Web (Streamlit)

```bash
streamlit run app/app.py
```

**Funcionalidades:**
- âœï¸ Escribe o pega cualquier comentario
- ğŸ” Click en "Clasificar Comentario"
- ğŸ“Š Visualiza resultados con probabilidades
- ğŸ”¬ Activa "AnÃ¡lisis Detallado" para comentarios tÃ³xicos

### API REST (FastAPI)

**Iniciar servidor:**
```bash
python run_api.py
# API disponible en http://localhost:8000
```

**Ejemplo de uso:**

```python
import requests
from requests.auth import HTTPBasicAuth

url = "http://localhost:8000/classify"
auth = HTTPBasicAuth("admin", "secret123")

response = requests.post(
    url,
    json={
        "text": "You are an idiot!",
        "include_probability": True,
        "include_detailed_classification": True
    },
    auth=auth
)

print(response.json())
```

**Endpoints disponibles:**
- `POST /classify` - Clasificar comentario individual
- `POST /classify-batch` - ClasificaciÃ³n por lotes
- `GET /health` - Estado del sistema
- `GET /stats` - EstadÃ­sticas de uso
- `GET /docs` - DocumentaciÃ³n interactiva (Swagger)

### Uso ProgramÃ¡tico

```python
import joblib

# Cargar modelos
vectorizer = joblib.load('artifacts/vectorizer.pkl')
clf = joblib.load('artifacts/model.pkl')

# Clasificar
comment = "This is a great article!"
X = vectorizer.transform([comment])
prediction = clf.predict(X)[0]
probability = clf.predict_proba(X)[0]

print(f"Toxic: {bool(prediction)}")
print(f"Confidence: {probability[1]:.2%}")
```

---

## ğŸ—ï¸ Estructura del Proyecto

```
toxic-comment-classifier/
â”‚
â”œâ”€â”€ ğŸ“ app/                          # AplicaciÃ³n Streamlit
â”‚   â””â”€â”€ app.py                       # Interfaz web principal
â”‚
â”œâ”€â”€ ğŸ“ api/                          # API REST
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main.py                      # Endpoints FastAPI
â”‚
â”œâ”€â”€ ğŸ“ artifacts/                    # Modelos entrenados
â”‚   â”œâ”€â”€ model.pkl                    # Modelo bÃ¡sico
â”‚   â”œâ”€â”€ vectorizer.pkl               # TF-IDF vectorizador
â”‚   â”œâ”€â”€ detailed_model.pkl           # Modelo multi-etiqueta
â”‚   â”œâ”€â”€ vectorizer_detailed.pkl      # Vectorizador detallado
â”‚   â””â”€â”€ toxicity_categories.pkl      # Lista de categorÃ­as
â”‚
â”œâ”€â”€ ğŸ“ notebooks/                    # AnÃ¡lisis y entrenamiento
â”‚   â”œâ”€â”€ 01_exploracion_dataset.ipynb     # EDA
â”‚   â”œâ”€â”€ 02_entrenamiento_modelo.ipynb    # Modelo bÃ¡sico
â”‚   â”œâ”€â”€ 03_guardar_modelo.ipynb          # Persistencia
â”‚   â””â”€â”€ 04_modelo_clasificacion_detallada.ipynb  # Modelo multi-etiqueta
â”‚
â”œâ”€â”€ ğŸ“ data/                         # Datasets (local)
â”‚   â””â”€â”€ data.csv
â”‚
â”œâ”€â”€ ğŸ“ scripts/                      # Utilidades
â”‚   â””â”€â”€ smoke_test.py                # Tests de validaciÃ³n
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt              # Dependencias Python
â”œâ”€â”€ ğŸ“„ Dockerfile                    # ConfiguraciÃ³n Docker
â”œâ”€â”€ ğŸ“„ run_api.py                    # Script para ejecutar API
â””â”€â”€ ğŸ“„ README.md                     # Este archivo
```

---

## ğŸ› ï¸ Stack TecnolÃ³gico

### Machine Learning & Data Science
- **scikit-learn** `1.7.1` - Modelos de clasificaciÃ³n (Logistic Regression)
- **pandas** `2.3.2` - ManipulaciÃ³n de datos
- **numpy** `2.3.2` - Operaciones numÃ©ricas
- **joblib** `1.5.1` - SerializaciÃ³n de modelos

### Frameworks Web
- **Streamlit** `1.48.1` - Interfaz web interactiva
- **FastAPI** `0.116.1` - API REST de alto rendimiento
- **Uvicorn** `0.35.0` - Servidor ASGI

### VisualizaciÃ³n
- **matplotlib** `3.10.5` - GrÃ¡ficos estÃ¡ticos
- **Altair** `5.5.0` - Visualizaciones interactivas

### Otros
- **PyJWT** `2.8.0` - AutenticaciÃ³n JWT
- **cryptography** `41.0.7` - Seguridad
- **Docker** - ContainerizaciÃ³n

---

## ğŸ“Š Rendimiento del Modelo

### Modelo BÃ¡sico (Binario)
- **Algoritmo**: Logistic Regression
- **VectorizaciÃ³n**: TF-IDF (10,000 features)
- **Accuracy**: ~92%
- **Vocabulario**: 10,000 palabras

### Modelo Detallado (Multi-etiqueta)
- **Algoritmo**: MultiOutputClassifier + Logistic Regression
- **VectorizaciÃ³n**: TF-IDF extendido
- **CategorÃ­as**: 29 tipos de toxicidad
- **Vocabulario**: 10,000+ palabras

---

## ğŸ” Seguridad

### API
- AutenticaciÃ³n HTTP Basic (usuario/contraseÃ±a)
- Rate Limiting: 100 requests/minuto por usuario
- ValidaciÃ³n de entrada con Pydantic

### ProducciÃ³n
> âš ï¸ **Nota**: Este proyecto es educativo/demostrativo. Para producciÃ³n:
> - Implementar autenticaciÃ³n robusta (OAuth2, JWT)
> - Usar base de datos para credenciales
> - Configurar CORS especÃ­fico
> - Implementar rate limiting con Redis
> - Agregar logging y monitoreo
> - Usar HTTPS

---

## ğŸ§ª Testing

### Smoke Test
```bash
python scripts/smoke_test.py
```

Verifica:
- âœ… Carga correcta de todos los artifacts
- âœ… Funcionalidad de predicciÃ³n bÃ¡sica
- âœ… Funcionalidad de predicciÃ³n detallada
- âœ… Integridad del vocabulario

---

## ğŸ“š Notebooks

### 1. ExploraciÃ³n del Dataset
`notebooks/01_exploracion_dataset.ipynb`
- AnÃ¡lisis exploratorio de datos (EDA)
- DistribuciÃ³n de clases
- AnÃ¡lisis de palabras frecuentes

### 2. Entrenamiento Modelo BÃ¡sico
`notebooks/02_entrenamiento_modelo.ipynb`
- Preprocesamiento de texto
- VectorizaciÃ³n TF-IDF
- Entrenamiento Logistic Regression
- EvaluaciÃ³n de mÃ©tricas

### 3. Guardar Modelos
`notebooks/03_guardar_modelo.ipynb`
- SerializaciÃ³n con joblib
- ValidaciÃ³n de artifacts

### 4. ClasificaciÃ³n Detallada
`notebooks/04_modelo_clasificacion_detallada.ipynb`
- Modelo multi-etiqueta
- 29 categorÃ­as de toxicidad
- AnÃ¡lisis granular

---

## ğŸš¢ Despliegue

### Local
```bash
streamlit run app/app.py
```

### Docker
```bash
docker build -t toxic-classifier .
docker run -p 8501:8501 toxic-classifier
```

### Streamlit Cloud
1. Sube el repo a GitHub
2. Conecta con [Streamlit Cloud](https://streamlit.io/cloud)
3. Deploy automÃ¡tico

### Heroku / Railway / Render
Compatible con cualquier plataforma que soporte Docker

---

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas! 

1. Fork el proyecto
2. Crea tu feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

---

## ğŸ“ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver archivo `LICENSE` para mÃ¡s detalles.

---

## ğŸ‘¨â€ğŸ’» Autor

**Daniel Moreno**

- GitHub: [@tu-usuario](https://github.com/tu-usuario)
- LinkedIn: [Tu Perfil](https://linkedin.com/in/tu-perfil)

---

## ğŸ™ Agradecimientos

- Dataset basado en [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)
- Inspirado en investigaciones de NLP y moderaciÃ³n de contenido
- Comunidad de scikit-learn y Streamlit

---

## ğŸ“§ Contacto

Â¿Preguntas? Â¿Sugerencias? Â¡ContÃ¡ctame!

- ğŸ“« Email: tu-email@ejemplo.com
- ğŸ’¼ LinkedIn: [Tu Perfil](https://linkedin.com/in/tu-perfil)
- ğŸ¦ Twitter: [@tu_usuario](https://twitter.com/tu_usuario)

---

<div align="center">

**â­ Si este proyecto te resulta Ãºtil, Â¡dale una estrella! â­**

Hecho con â¤ï¸ y â˜• por Daniel Moreno

</div>
